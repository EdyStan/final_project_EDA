# inspect the new data frame
str(imputed_Data)
column_type <- class(imputed_Data$Severity)
print(column_type)
# first, we want to create training and test sets
# install.packages("caret")
library(caret)
# smth like random_state from Python
set.seed(1)
# p is the proportion of data that is included in the training set
train_indices <- createDataPartition(imputed_Data$Severity, p = 0.8, list = FALSE)
# here we create train and test sets
train_data <- imputed_Data[train_indices, ]
test_data <- imputed_Data[-train_indices, ]
# we import the randomForest library
library(randomForest)
random_forest_model <- randomForest(Severity ~ BI.RADS.assessment + Age + Shape + Malign + Density,
data = train_data,
ntree = 200)
# Make predictions on the 'unseen' test set
predictions <- predict(random_forest_model, newdata = test_data)
# Evaluate the final model
confusion_matrix <- confusionMatrix(predictions, test_data$Severity)
# extract statistics from the confusion matrix
accuracy <- confusion_matrix$overall["Accuracy"]
precision <- confusion_matrix$byClass["Precision"]
recall <- confusion_matrix$byClass["Recall"]
f1_score <- confusion_matrix$byClass["F1"]
# print the evaluation results
print(paste("Accuracy:", accuracy))
print(paste("Precision:", precision))
print(paste("Recall:", recall))
print(paste("F1 Score:", f1_score))
library(ggplot2)
ggplot(Data, aes(x = target_variable)) +
geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Target Variable", x = "Target Variable", y = "Frequency")
library(ggplot2)
ggplot(Data, aes(x = Data$Severity)) +
geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Target Variable", x = "Severity", y = "Frequency")
ggplot(Data, aes(x = Data$Severity)) +
geom_bar(binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Target Variable", x = "Severity", y = "Frequency")
ggplot(Data, aes(x = Data$Severity)) +
geom_bar(binwidth = 1, fill = "blue", color = "black", alpha = 0.5) +
labs(title = "Histogram of Target Variable", x = "Severity", y = "Frequency")
ggplot(Data, aes(x = Data$Severity)) +
geom_bar(binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Target Variable", x = "Severity", y = "Frequency")
ggplot(Data, aes(x = Data$Severity)) +
geom_bar(binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
ggplot(Data, aes(x = Data$Severity)) +
geom_bar(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
ggplot(Data, aes(x = Data$Severity)) +
geom_bar(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
levels(Data$Severity)
ggplot(na.omit(Data), aes(x = na.omit(Data$Severity))) +
geom_bar(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
levels(Data$Severity)
ggplot(na.omit(Data), aes(x = na.omit(Data$Severity))) +
geom_bar(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
levels(Data$Severity)
ggplot(Data, aes(x = Data$Severity)) +
geom_bar(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
print(Data$Severity)
ggplot(imputed_Data, aes(x = imputed_Data$Severity)) +
geom_bar(fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
ggplot(imputed_Data, aes(x = imputed_Data$Severity)) +
geom_bar(width=0.5, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
ggplot(imputed_Data, aes(x = imputed_Data$Severity)) +
geom_bar(width=0.7, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
# load data into a data frame using read.csv function
Data =  as.data.frame(read.csv("data/mammographic_masses.data"))
# preview the data frame. We observe that missing values are represented by "?"
# and types are not ideal (chr for int values)
str(Data)
dim(Data)
# convert "?" to NA so that the interpreter can see these values as missing values
Data[Data == "?"] <- NA
# now, change types of the columns. We use 'factor' type for the categorical values
# (such as our label, 'Severity' column, which can have only two values)
# as 'Age' column has a wide range of values, we keep it integer.
Data$BI.RADS.assessment <- as.factor(Data$BI.RADS.assessment)
Data$Age <- as.integer(Data$Age)
Data$Shape <- as.factor(Data$Shape)
Data$Malign <- as.factor(Data$Malign)
Data$Density <- as.factor(Data$Density)
Data$Severity <- as.factor(Data$Severity)
# there is only one occurrence of value "55" in the whole BI.RADS.assessment feature
# so we decide to remove it completely. After we do that, we drop the unused levels.
Data <- Data[Data$BI.RADS.assessment != "55", ]
Data$BI.RADS.assessment <- droplevels(Data$BI.RADS.assessment)
# inspect the data frame once again to see the results
str(Data)
# count the missing values in each column
missing_values <- colSums(is.na(Data))
# print the number of missing values. As we can see, missing values are far from
# a few. We have the options impute or remove the rows with missing values.
# we decide to impute them
print(missing_values)
# 'mice': R package for Multivariate Imputation by Chained Equations.
# It imputes missing values using regression models, iteratively updating variables.
# Multiple imputations are generated for uncertainty consideration.
# (Multiple imputations involve creating several versions of the data frame,
# each with different imputed values for the missing data. These datasets
# collectively reflect the uncertainty about the true values of the missing observations.)
#install.packages("mice")
library(mice)
# impute data and create the updated data frame
imputed_model <- mice(Data)
imputed_Data <- complete(imputed_model)
# inspect the new data frame
str(imputed_Data)
# plot the distribution of values for the label
library(ggplot2)
ggplot(imputed_Data, aes(x = imputed_Data$Severity)) +
geom_bar(width=0.7, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
column_type <- class(imputed_Data$Severity)
ggplot(data, aes(x = predictions, y = test_data$Severity)) +
geom_point(color = "blue", alpha = 0.7) +
labs(title = "Scatter Plot of Predictor vs. Target", x = "Predictor Variable", y = "Target Variable")
ggplot(Data, aes(x = predictions, y = test_data$Severity)) +
geom_point(color = "blue", alpha = 0.7) +
labs(title = "Scatter Plot of Predictor vs. Target", x = "Predictor Variable", y = "Target Variable")
ggplot(test_data, aes(x = predictions, y = test_data$Severity)) +
geom_point(color = "blue", alpha = 0.7) +
labs(title = "Scatter Plot of Predictor vs. Target", x = "Predictor Variable", y = "Target Variable")
# load data into a data frame using read.csv function
Data =  as.data.frame(read.csv("data/mammographic_masses.data"))
# preview the data frame. We observe that missing values are represented by "?"
# and types are not ideal (chr for int values)
str(Data)
dim(Data)
# convert "?" to NA so that the interpreter can see these values as missing values
Data[Data == "?"] <- NA
# now, change types of the columns. We use 'factor' type for the categorical values
# (such as our label, 'Severity' column, which can have only two values)
# as 'Age' column has a wide range of values, we keep it integer.
Data$BI.RADS.assessment <- as.factor(Data$BI.RADS.assessment)
Data$Age <- as.integer(Data$Age)
Data$Shape <- as.factor(Data$Shape)
Data$Malign <- as.factor(Data$Malign)
Data$Density <- as.factor(Data$Density)
Data$Severity <- as.factor(Data$Severity)
# there is only one occurrence of value "55" in the whole BI.RADS.assessment feature
# so we decide to remove it completely. After we do that, we drop the unused levels.
Data <- Data[Data$BI.RADS.assessment != "55", ]
Data$BI.RADS.assessment <- droplevels(Data$BI.RADS.assessment)
# inspect the data frame once again to see the results
str(Data)
# count the missing values in each column
missing_values <- colSums(is.na(Data))
# print the number of missing values. As we can see, missing values are far from
# a few. We have the options impute or remove the rows with missing values.
# we decide to impute them
print(missing_values)
# 'mice': R package for Multivariate Imputation by Chained Equations.
# It imputes missing values using regression models, iteratively updating variables.
# Multiple imputations are generated for uncertainty consideration.
# (Multiple imputations involve creating several versions of the data frame,
# each with different imputed values for the missing data. These datasets
# collectively reflect the uncertainty about the true values of the missing observations.)
#install.packages("mice")
library(mice)
# impute data and create the updated data frame
imputed_model <- mice(Data)
imputed_Data <- complete(imputed_model)
# inspect the new data frame
str(imputed_Data)
# plot a histogram to illustrate the distribution of values for the label
library(ggplot2)
ggplot(imputed_Data, aes(x = imputed_Data$Severity)) +
geom_bar(width=0.7, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
column_type <- class(imputed_Data$Severity)
print(column_type)
# first, we want to create training and test sets
#install.packages("caret")
library(caret)
# smth like random_state from Python
set.seed(1)
# p is the proportion of data that is included in the training set
train_indices <- createDataPartition(imputed_Data$Severity, p = 0.8, list = FALSE)
# here we create train and test sets
train_data <- imputed_Data[train_indices, ]
test_data <- imputed_Data[-train_indices, ]
logistic_regression_model <- glm(Severity ~ BI.RADS.assessment + Age + Shape + Malign + Density,
data = train_data,
family = "binomial")
levels(train_data$BI.RADS.assessment)  # Check levels in training data
levels(test_data$BI.RADS.assessment)
# Make predictions on the 'unseen' test set
predictions <- as.factor(as.numeric(predict(logistic_regression_model, newdata = test_data, type = "response") > 0.5))
# Evaluate the final model
confusion_matrix <- confusionMatrix(predictions, test_data$Severity)
# extract statistics from the confusion matrix
accuracy <- confusion_matrix$overall["Accuracy"]
precision <- confusion_matrix$byClass["Precision"]
recall <- confusion_matrix$byClass["Recall"]
f1_score <- confusion_matrix$byClass["F1"]
# print the evaluation results
print(paste("Accuracy:", accuracy))
print(paste("Precision:", precision))
print(paste("Recall:", recall))
print(paste("F1 Score:", f1_score))
ggplot(test_data, aes(x = predictions, y = test_data$Severity)) +
geom_point(color = "blue", alpha = 0.7) +
labs(title = "Scatter Plot of Predictor vs. Target", x = "Predictor Variable", y = "Target Variable")
library(pROC)
# Assuming 'model' is your logistic regression model and 'data' is your data frame
roc_curve <- roc(test_data$Severity, predictions)
# Plot ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
target <- factor(test_data$Severity, ordered=TRUE)
roc_curve <- roc(target, predictions)
pred <- factor(predicitions, ordered=TRUE)
roc_curve <- roc(target, predictions)
pred <- factor(predictions, ordered=TRUE)
roc_curve <- roc(target, predictions)
roc_curve <- roc(target, pred)
# Plot ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
# Plot ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(1, 0))
# Plot ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(0, 1))
# Plot ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(1, 0), ylim=c(0,1))
# load data into a data frame using read.csv function
Data =  as.data.frame(read.csv("data/mammographic_masses.data"))
# preview the data frame. We observe that missing values are represented by "?"
# and types are not ideal (chr for int values)
str(Data)
dim(Data)
# convert "?" to NA so that the interpreter can see these values as missing values
Data[Data == "?"] <- NA
# now, change types of the columns. We use 'factor' type for the categorical values
# (such as our label, 'Severity' column, which can have only two values)
# as 'Age' column has a wide range of values, we keep it integer.
Data$BI.RADS.assessment <- as.factor(Data$BI.RADS.assessment)
Data$Age <- as.integer(Data$Age)
Data$Shape <- as.factor(Data$Shape)
Data$Malign <- as.factor(Data$Malign)
Data$Density <- as.factor(Data$Density)
Data$Severity <- as.factor(Data$Severity)
# there is only one occurrence of value "55" in the whole BI.RADS.assessment feature
# so we decide to remove it completely. After we do that, we drop the unused levels.
Data <- Data[Data$BI.RADS.assessment != "55", ]
Data$BI.RADS.assessment <- droplevels(Data$BI.RADS.assessment)
# inspect the data frame once again to see the results
str(Data)
# count the missing values in each column
missing_values <- colSums(is.na(Data))
# print the number of missing values. As we can see, missing values are far from
# a few. We have the options impute or remove the rows with missing values.
# we decide to impute them
print(missing_values)
# 'mice': R package for Multivariate Imputation by Chained Equations.
# It imputes missing values using regression models, iteratively updating variables.
# Multiple imputations are generated for uncertainty consideration.
# (Multiple imputations involve creating several versions of the data frame,
# each with different imputed values for the missing data. These datasets
# collectively reflect the uncertainty about the true values of the missing observations.)
#install.packages("mice")
library(mice)
# impute data and create the updated data frame
imputed_model <- mice(Data)
imputed_Data <- complete(imputed_model)
# inspect the new data frame
str(imputed_Data)
# plot a histogram to illustrate the distribution of values for the label
library(ggplot2)
ggplot(imputed_Data, aes(x = imputed_Data$Severity)) +
geom_bar(width=0.7, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histogram of Severity", x = "Severity", y = "Frequency")
column_type <- class(imputed_Data$Severity)
print(column_type)
# first, we want to create training and test sets
#install.packages("caret")
library(caret)
# smth like random_state from Python
set.seed(1)
# p is the proportion of data that is included in the training set
train_indices <- createDataPartition(imputed_Data$Severity, p = 0.8, list = FALSE)
# here we create train and test sets
train_data <- imputed_Data[train_indices, ]
test_data <- imputed_Data[-train_indices, ]
logistic_regression_model <- glm(Severity ~ BI.RADS.assessment + Age + Shape + Malign + Density,
data = train_data,
family = "binomial")
levels(train_data$BI.RADS.assessment)  # Check levels in training data
levels(test_data$BI.RADS.assessment)
# Make predictions on the 'unseen' test set
predictions <- as.factor(as.numeric(predict(logistic_regression_model, newdata = test_data, type = "response") > 0.5))
# Evaluate the final model
confusion_matrix <- confusionMatrix(predictions, test_data$Severity)
# extract statistics from the confusion matrix
accuracy <- confusion_matrix$overall["Accuracy"]
precision <- confusion_matrix$byClass["Precision"]
recall <- confusion_matrix$byClass["Recall"]
f1_score <- confusion_matrix$byClass["F1"]
# print the evaluation results
print(paste("Accuracy:", accuracy))
print(paste("Precision:", precision))
print(paste("Recall:", recall))
print(paste("F1 Score:", f1_score))
# plot the ROC curve of our label and the predicted data.
# the input variables need to be numerical or ordered, so we decided to order them
library(pROC)
target <- factor(test_data$Severity, ordered=TRUE)
pred <- factor(predictions, ordered=TRUE)
roc_curve <- roc(target, pred)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(1, 0), ylim=c(0,1))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(1, 0), ylim=c(0,1))+
theme(
panel.background = element_blank(),
axis.title.x = element_text(size =18, face = 'bold'),
axis.title.y = element_text(size =18, face = 'bold'),
panel.border = element_rect(size = 2, fill = NA),
axis.text.x = element_text(size = 14, face ='bold'),
axis.text.y = element_text(size = 14, face ='bold')) +
xlab('100% - Specificity') +
ylab('100% - Sensitivity') +
scale_x_continuous(breaks = seq(0,1,0.25), labels = seq(0,1,0.25) * 100) +
scale_y_continuous(breaks = seq(0,1,0.25), labels = seq(0,1,0.25) * 100)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, mar = c(5, 5, 4, 2))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, mar = c(10, 5, 4, 2))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, mar = c(2, 5, 4, 2))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, mar = c(1, 5, 4, 2))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, mar = c(4, 5, 4, 2))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(2,3))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(1,3))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(0,3))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(0,1))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(0.2,0.8))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(0.7,0.8))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(0.7,0.4))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlim=c(0.7,0.6))
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2, xlab="Precision", ylab="Recall")
heatmap(imputed_Data,
col = colorRampPalette(c("white", "blue"))(20),
scale = "column",
main = "Heatmap Example",
xlab = "X-axis Label",
ylab = "Y-axis Label")
numeric_data <- as.numeric(imputed_Data)
numeric_data <- as.numeric(as.matrix(imputed_Data))
heatmap(numeric_data,
col = colorRampPalette(c("white", "blue"))(20),
scale = "column",
main = "Heatmap Example",
xlab = "X-axis Label",
ylab = "Y-axis Label")
str(numeric_data)
numeric_data[] <- lapply(imputed_Data, function(x) as.numeric(as.character(x)))
str(numeric_data)
heatmap(numeric_data,
col = colorRampPalette(c("white", "blue"))(20),
scale = "column",
main = "Heatmap Example",
xlab = "X-axis Label",
ylab = "Y-axis Label")
heatmap(as.matrix(numeric_data),
col = colorRampPalette(c("white", "blue"))(20),
scale = "column",
main = "Heatmap Example",
xlab = "X-axis Label",
ylab = "Y-axis Label")
numeric_data[] <- lapply(imputed_Data, function(x) as.numeric(as.character(x)))
str(numeric_data)
heatmap(as.matrix(numeric_data),
col = colorRampPalette(c("white", "blue"))(20),
scale = "column",
main = "Heatmap Example",
xlab = "X-axis Label",
ylab = "Y-axis Label")
numeric_Data$BI.RADS.assessment <- as.numeric(Data$BI.RADS.assessment)
numeric_Data <- data.frame()
numeric_Data$BI.RADS.assessment <- as.numeric(Data$BI.RADS.assessment)
numeric_Data <- data.frame(
BI.RADS.assessment = as.numeric(Data$BI.RADS.assessment),
Age = as.numeric(Data$Age),
Shape = as.numeric(Data$Shape),
Malign = as.numeric(Data$Malign),
Density = as.numeric(Data$Density),
Severity = as.numeric(Data$Severity)
)
str(numeric_data)
heatmap(as.matrix(numeric_data),
col = colorRampPalette(c("white", "blue"))(20),
scale = "column",
main = "Heatmap Example",
xlab = "X-axis Label",
ylab = "Y-axis Label")
heatmap(as.matrix(numeric_data),
scale = "column",
main = "Heatmap Example",
xlab = "X-axis Label",
ylab = "Y-axis Label")
heatmap(as.matrix([[1, 2, 2], [3, 3, 3]]),
str(numeric_Data)
numeric_Data <- data.frame(
BI.RADS.assessment = as.numeric(imputed_Data$BI.RADS.assessment),
Age = as.numeric(imputed_Data$Age),
Shape = as.numeric(imputed_Data$Shape),
Malign = as.numeric(imputed_Data$Malign),
Density = as.numeric(imputed_Data$Density),
Severity = as.numeric(imputed_Data$Severity)
)
str(numeric_Data)
heatmap(as.matrix(numeric_Data),
scale = "column",
main = "Heatmap Example",
xlab = "X-axis Label",
ylab = "Y-axis Label")
library(ggplot2)
ggplot(numeric_Data, aes(x = x, y = y, fill = value)) +
geom_tile()
heatmap(as.matrix(numeric_Data),
scale = "column",
main = "Heatmap Example",
xlab = "X-axis Label",
ylab = "Y-axis Label")
library(mice)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(class)
library(pROC)
# load data into a data frame using read.csv function
Data =  as.data.frame(read.csv("mammographic_masses.data"))
# preview the data frame. We observe that missing values are represented by "?"
# and types are not ideal (chr for int values)
str(Data)
setwd("~/Desktop/master_AI/eda/final_project_EDA")
library(mice)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(class)
library(pROC)
# load data into a data frame using read.csv function
Data =  as.data.frame(read.csv("mammographic_masses.data"))
# preview the data frame. We observe that missing values are represented by "?"
# and types are not ideal (chr for int values)
str(Data)
library(mice)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(class)
library(pROC)
# load data into a data frame using read.csv function
Data =  as.data.frame(read.csv("mammographic_masses.data"))
# preview the data frame. We observe that missing values are represented by "?"
# and types are not ideal (chr for int values)
str(Data)
# load data into a data frame using read.csv function
Data =  as.data.frame(read.csv("data/mammographic_masses.data"))
# preview the data frame. We observe that missing values are represented by "?"
# and types are not ideal (chr for int values)
str(Data)
dim(Data)
# convert "?" to NA so that the interpreter can see these values as missing values
Data[Data == "?"] <- NA
# now, change types of the columns. We use 'factor' type for the categorical values
# (such as our label, 'Severity' column, which can have only two values)
# as 'Age' column has a wide range of values, we keep it integer.
Data$BI.RADS.assessment <- as.factor(Data$BI.RADS.assessment)
Data$Age <- as.integer(Data$Age)
Data$Shape <- as.factor(Data$Shape)
Data$Margin <- as.factor(Data$Margin)
Data$Density <- as.factor(Data$Density)
library(mice)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(class)
library(pROC)
# load data into a data frame using read.csv function
Data =  as.data.frame(read.csv("data/mammographic_masses.data"))
# preview the data frame. We observe that missing values are represented by "?"
# and types are not ideal (chr for int values)
str(Data)
dim(Data)
# convert "?" to NA so that the interpreter can see these values as missing values
Data[Data == "?"] <- NA
# now, change types of the columns. We use 'factor' type for the categorical values
# (such as our label, 'Severity' column, which can have only two values)
# as 'Age' column has a wide range of values, we keep it integer.
Data$BI.RADS.assessment <- as.factor(Data$BI.RADS.assessment)
Data$Age <- as.integer(Data$Age)
Data$Shape <- as.factor(Data$Shape)
Data$Margin <- as.factor(Data$Margin)
Data$Density <- as.factor(Data$Density)
print(Data$Margin)
